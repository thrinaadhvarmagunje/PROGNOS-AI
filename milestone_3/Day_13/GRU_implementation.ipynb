{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3d6a8fb",
   "metadata": {},
   "source": [
    "### Implementation of GRU on the time-series dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51a0c8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a0a8299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test feature shape: (17631, 30, 66)\n",
      "Test target shape: (17631,)\n"
     ]
    }
   ],
   "source": [
    "# Load test features and labels\n",
    "X_test = np.load('rolling_window_sequences.npy')  # Replace with actual file path\n",
    "metadata_test = pd.read_csv(\"sequence_metadata_with_RUL.csv\")  # Replace with actual file path\n",
    "y_test = metadata_test[\"RUL\"].values\n",
    "print(\"Test feature shape:\", X_test.shape)\n",
    "print(\"Test target shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d11f681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and validation sets (assuming no separate train set given)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_test, y_test, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cd59e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GRU model creation function\n",
    "def create_gru_model(input_shape, units=64, learning_rate=0.001, dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units, input_shape=input_shape))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a37d6001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\win10\\python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = create_gru_model(input_shape=(X_train.shape[1], X_train.shape[2]), units=64, learning_rate=0.001, dropout_rate=0.2)\n",
    "\n",
    "# Callbacks for early stopping\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb4d5f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 7619.3813 - mae: 76.0429 - val_loss: 5854.6714 - val_mae: 64.8472\n",
      "Epoch 2/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 5497.6406 - mae: 62.4432 - val_loss: 4534.1670 - val_mae: 55.4343\n",
      "Epoch 3/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 4244.8384 - mae: 53.2952 - val_loss: 3528.2424 - val_mae: 47.8430\n",
      "Epoch 4/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 3336.0378 - mae: 46.5107 - val_loss: 2747.3362 - val_mae: 41.5641\n",
      "Epoch 5/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 2621.5093 - mae: 40.6729 - val_loss: 2144.2107 - val_mae: 36.4552\n",
      "Epoch 6/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 2047.4005 - mae: 35.6209 - val_loss: 1673.6516 - val_mae: 32.0420\n",
      "Epoch 7/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 1573.0201 - mae: 31.2573 - val_loss: 1285.1062 - val_mae: 28.0503\n",
      "Epoch 8/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 1234.8544 - mae: 27.8473 - val_loss: 993.8656 - val_mae: 24.9697\n",
      "Epoch 9/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 948.2743 - mae: 24.4777 - val_loss: 775.8102 - val_mae: 22.2035\n",
      "Epoch 10/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 756.0471 - mae: 21.9707 - val_loss: 626.7018 - val_mae: 20.1407\n",
      "Epoch 11/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 623.4128 - mae: 20.1743 - val_loss: 529.2841 - val_mae: 18.6492\n",
      "Epoch 12/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 522.7701 - mae: 18.5593 - val_loss: 441.0798 - val_mae: 16.9272\n",
      "Epoch 13/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 443.8633 - mae: 17.1098 - val_loss: 387.8159 - val_mae: 16.2301\n",
      "Epoch 14/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 400.6584 - mae: 16.2659 - val_loss: 327.1829 - val_mae: 14.7542\n",
      "Epoch 15/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 354.3896 - mae: 15.2228 - val_loss: 293.8290 - val_mae: 13.7032\n",
      "Epoch 16/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 322.6917 - mae: 14.5678 - val_loss: 257.8295 - val_mae: 13.0497\n",
      "Epoch 17/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 292.7097 - mae: 13.7926 - val_loss: 253.4145 - val_mae: 12.4977\n",
      "Epoch 18/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 258.8710 - mae: 12.8467 - val_loss: 223.7041 - val_mae: 11.7460\n",
      "Epoch 19/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 241.5479 - mae: 12.2207 - val_loss: 234.4098 - val_mae: 11.7249\n",
      "Epoch 20/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 231.4727 - mae: 11.8728 - val_loss: 173.2715 - val_mae: 10.4950\n",
      "Epoch 21/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 213.8137 - mae: 11.3937 - val_loss: 197.1400 - val_mae: 10.9975\n",
      "Epoch 22/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 203.1104 - mae: 11.0107 - val_loss: 157.8582 - val_mae: 9.7459\n",
      "Epoch 23/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 193.3571 - mae: 10.6815 - val_loss: 153.3026 - val_mae: 9.4266\n",
      "Epoch 24/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 182.6355 - mae: 10.4111 - val_loss: 151.5558 - val_mae: 9.1608\n",
      "Epoch 25/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 177.8454 - mae: 10.2213 - val_loss: 154.3064 - val_mae: 9.2095\n",
      "Epoch 26/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 193.0696 - mae: 10.5863 - val_loss: 129.2860 - val_mae: 8.4311\n",
      "Epoch 27/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 156.1719 - mae: 9.5668 - val_loss: 122.6925 - val_mae: 8.3100\n",
      "Epoch 28/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 160.9639 - mae: 9.7432 - val_loss: 124.2614 - val_mae: 8.4130\n",
      "Epoch 29/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 153.8010 - mae: 9.4738 - val_loss: 118.2112 - val_mae: 8.0871\n",
      "Epoch 30/30\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 149.6253 - mae: 9.3168 - val_loss: 143.9138 - val_mae: 8.5283\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01343acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 118.2111, MAE: 8.0871\n",
      "\u001b[1m551/551\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "Test MSE: 102.2187\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "val_loss, val_mae = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f'Validation MSE: {val_loss:.4f}, MAE: {val_mae:.4f}')\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "# Calculate test MSE\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Test MSE: {test_mse:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051696c2",
   "metadata": {},
   "source": [
    "Task: Build and train a GRU (Gated Recurrent Unit) neural network model for sequence regression on a given dataset. The implementation must include the following features:\n",
    "\n",
    "Use of callbacks such as EarlyStopping to prevent overfitting and ModelCheckpoint to save the best model.\n",
    "\n",
    "Hyperparameter tuning for model parameters like number of GRU units, learning rate, and dropout rate.\n",
    "\n",
    "Cross-validation (e.g., K-Fold) to robustly evaluate model performance across different data splits.\n",
    "\n",
    "Reporting of evaluation metrics such as mean squared error (MSE) and mean absolute error (MAE)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
